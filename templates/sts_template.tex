\documentclass[CUx,lsstdraft,STS]{lsstdoc}

\begin{document}

%set the WP number or product here for the requirements 
\def\product{PROD}

\setDocCompact{true}

%Product name first in title 
\setDocTitle    [STS for \product]
                    {\color[rgb]{0.16,0.42,0.57} \sf \product ~Software Test Specification} 
                    
\setDocAuthor   {theAuthor}                % the author(s)
\setDocApprove  {theApprover}              % approval by ...
\setDocRef      {LDM-xxxx} % the reference code
\setDocIssue    {0D}                        % the issue
\setDocRevision {1}                        % the revision
\setDocDate     {\today}              % the date of the issue
\setDocStatus   {draft}                    % the document status
% Comment out the setLSSTDU if you do not want it do not set it to Blanck
\setLSSTDU          {DUy}                      % the DU within your CU
 
%
% a short abstract
%
\setDocAbstract {This is a template for the Software Test Specification document for \product. It encompasses the test design,
test case and test procedure specification.}

%
% the title page
%
\mktitle

%
%	Revision history MOST RECENT FIRST
%
\begin{docHistory}
\addtohist{D}{1}{yyyy-mm-dd}{WOM}{First draft}
\end{docHistory}

%
%	TOC
%
\newpage
\setcounter{tocdepth}{2}
\tableofcontents
\newpage

\section{Introduction \label{sect:intro}}
This section should provide an overview of the entire document and a description of the scope of testing.

\subsection{Objectives \label{sect:objectives}}
Test specification document helps in refining the test approach that was planned for executing the test plan. It identifies
the test cases, procedures and the pass/fail criteria for the assignment. It outlines the actual values required as input parameters
in the testing process and the expected outputs of the testing results. It also identifies the various constraints related to the
test case. \\It is important to note that test cases can be reusable components and one test case can be used in various test designs.\\
The test procedure outlines all the processes that are required to test the system and implement the test cases.

\subsection{Scope \label{sect:scope}}
Define the scope (refining the detailed in the Software Test Plan \citell{LL:RG-004}) of the testing whose specifications are
described in this document.

\subsection{Applicable Documents \label{sect:appdocs}}
\addtocounter{table}{-1}

\begin{tabular}[htb]{l l}
\citell{LL:RG-004}& DPAC Software Test Plan\\
\citell{LL:RD-010}& Gaia DPAC Project Development Plan\\
\citell{LL:TL-001}& DPAC Product Assurance Plan \\
\citell{LL:WOM-011}& DPAC Software Engineering Guidelines \\
\citell{LL:TLO-001} & ECSS Tailoring \\
\end{tabular}

\subsection{References\label{sect:references}}
\renewcommand{\refname}{}
\bibliographystyle{gaia_aa}
\bibliography{gaia_livelink_valid,gaia_drafts,gaia_refs,gaia_books,gaia_refs_ads}

\subsection{Definitions, acronyms, and abbreviations \label{sect:acronyms}} % include acronyms.tex generated by the acronyms.csh (GaiaTools)
\input{acronyms}

\subsection{Document Overview \label{sect:docoverview}}
This section shall describe the contents of the document and explains how the rest of the report is organized.

\newpage

%----------------------------------------------------
% TASK IDENTIFICATION - APPROACH
%----------------------------------------------------
\section{Approach \label{sect:Approach}}
Describe the approach to be utilized for the software testing specification. It should identify the major activities, methods
and tools that are to be used to test the designated group of features.
\subsection{Tasks and criteria \label{sect:tasks}}
Describe which are the items under tests, as well as criteria to be utilized. Activities should be described in sufficient detail
to allow identification of the major testing tasks and estimation of the resources and time needed for the tests. 
\subsection{Features to be tested \label{sect:feat2tested}}
Describe the GENERAL features to be tested.
\subsection{Features not to be tested \label{sect:featnot2tested}}
Describe all the features and significant combinations not to be tested and explain why. If it is not possible to test some
features at their most appropriate level of testing but which will be tested at a later level, this information should be
included here
\subsection{Pass - Fail criteria \label{sect:passfail}}
GENERAL criteria to be used to determine whether or not tests are passed.
\subsection{Suspension criteria and resumption requirements \label{suspension}}
Describe the criteria used to suspend all, or a part of, the testing activities on the test items associated with
the plan, as well as the activities to be repeated when testing is resumed.
\subsection{Testing Procedure Compliance \label{sect:testprocedure}}
This section must specify whether the system adheres to the testing procedure defined in \citell{LL:RG-004} or not.\\
In case it adheres to it it can state something like: "The System testing is in compliance with the Testing Procedure defined for DPAC, consisting on a Test Readiness
Review and a Test Review Board (details in \citell{LL:RG-004}). The Test Review Board members are ..."

\newpage


%--------------------
% NAMING CONVENTION
%--------------------
% The naming convention adopted for the test design/test cases is:
% TARGET-PROD-SUBSYST-SCOPE-XX-YY
% e.g. CU3-IDT-XM-VAL-10-05
% being
% TARGET: CU or DPC (CU1/2/3/4/... and DPCE/T/B...)
% PROD: product or system (IDT, FL, AGIS, etc)
% SUBSYST: subsystem (e.g. XM of IDT. If it is a test of the whole system then SUBSYST = PROD
% SCOPE: type of tests (but it could be extended in case the needs of the CU)
%	FUN: concerning functional testing
%	PRF: concerning performance testing
%	INT: concerning integration testing
%	MNT: concerning maintenance testing
% 	ACP: concerning acceptance testing
%	REG: concerning regression testing
%	INS: concerning installation testing
%	BCK: concerning backup and restore testing
%	ITF: concerning interface testing
% XX: test design number (from ten to ten - i.e. 10, 20, 30...)
% YY: test case number (from five to five - i.e. 05, 10, 15...)


%--------------------------------------------------
% SPECIFICATION DESIGN OVERVIEW
%--------------------------------------------------
\section{Specification Design Overview \label{sect:design}}
Specify refinements of the test approach described in \citell{LL:RG-004} if any.
If not suppress this section .

% NON-TESTING VERIFICATION METHODS TEST DESIGN
\section{\CU-\product-SUBSYST-VER-XX \label{sect:designid_verification}}

\subsection{Objective \label{sect:designobj}}
This test design includes all the verification methods different to the dynamic testing, needed for the
demonstration of the fulfillment of specific requirements of the SRS.\\
These are the requirements that do not need the execution of the software systems, but a careful document or code inspection, review
or analysis.

\subsection{Features to be tested \label{sect:totest}}
Identify the test items and describe the features and combinations of features that are the object of this design
specification. E.g.:\\
\begin{itemize}
\item Demonstrate that the CU has produced an specific document (e.g. the Software Development Plan)
\item Demonstrate the behaviour or value of an specific parameter (e.g. "As a minimum the PPN parameter shall be included in
the global model"
\item Static analysis using tools such as Findbugs or checkstyle, etc.
\item etc
\end{itemize}
The features to be tested depends on the content of the Software Requirements Document. Therefore the above list is just
an example.

\subsection{Approach refinements \label{sect:approach}}
Specify the verification methods to be used to verify the features describe in the section above. These methods are
described in the DPAC SVTP \citellp{LL:RG-004}. E.g.:
\begin{itemize}
\item Code inspection
\item Document inspection
\item Review
\item Static analysis
\item etc
\end{itemize}

\subsection{Test case identification \label{sect:testcaselist}}
List the identifier and a brief description of each test case associated with this design.

\begin{longtable} {|p{0.4\textwidth}|p{0.6\textwidth}|}\hline
{\bf Test Case}  & {\bf Description}  \\\hline
\CU-\product-SUBSYST-VER-XX-05 & SDP inspection  \\\hline
\CU-\product-SUBSYST-VER-XX-10 & SDD inspection \\\hline
\CU-\product-SUBSYST-VER-XX-15 & Code inspection \\\hline
\CU-\product-SUBSYST-VER-XX-20 & Testing review \\\hline
etc & \\\hline
\end{longtable}
The number and scope of the test cases depend on the requirements to be verified. The list provide above is only an example.

\subsection{Feature pass/fail criteria \label{sect:passfail}}
Specify the specific criteria for this design to be used to determine whether the feature or feature combination has passed or failed.

% NON-TESTING VERIFICATION METHODS TEST CASES
\subsection{Test Case \CU-\product-SUBSYST-VER-XX-YY \label{sect:testcaseid}}

\subsubsection{Requirements \label{sect:reqs}}
Specify the requirements that fulfill the test case, comma-separated and ending with '.'\\
e.g. CU3-IDT-XM-FUN-30,CU3-IDT-ASD-FUN-20.\\
Note that the format is essential for the script that creates the traceability matrices works fine.

\subsubsection{Test items \label{sect:tcitems}}
Identify and briefly describe the items and features to be exercised by this test case (e.g.:
\begin{itemize}
\item  demonstrate that an
specific document is written or that it contains the information required
\item or...
\item demonstrate that a parameter is set to a specific value
\item or...
\item the code is written in java
\end{itemize}

\subsubsection{Intercase dependencies \label{interface_dependencies}}
List the identifiers of the test cases that must be executed prior to this test case. Summarize the nature of the dependencies.

\subsubsection{Procedure \label{procedures}}
If the procedure is shared by various test cases it would be recommended to separate the procedure description from the test
case definition. Thus, only a reference to the procedure identification shall be provided. The complete description of
the test procedure shall be given otherwise. \\

Describe any special constraints on the test procedures that execute this test case. These constraints may involve special set
up, operator intervention, output determination procedures, and special wrap up.


\section{\CU-\product-SUBSYST-SCOPE-XX \label{sect:designid}}

\subsection{Objective \label{sect:designobj}}
Specify the objective of this test design.

\subsection{Features to be tested \label{sect:totest}}
Identify the test items and describe the features and combinations of features that are the object of this design
specification. Other features may be exercised, but need not be identified.\\
For each feature or feature combination, a reference to its associated requirements should be included.

\subsection{Approach refinements \label{sect:approach}}
Specify refinements to the approach described in the test plan. Include specific test techniques to be used.
The method on analysing test results should be identified.\\
Specify the results of any analysis that provides a rationale for test case selection.\\
Summarize the common attributes of any test cases. This may include input constraints that must be true for every input
in the set of associated test cases, any shared environmental needs, any shared special procedural requirements and any
shared case dependencies.

\subsection{Test case identification \label{sect:testcaselist}}
List the identifier and a brief description of each test case associated with this design.

\begin{longtable} {|p{0.4\textwidth}|p{0.6\textwidth}|}\hline
{\bf Test Case}  & {\bf Description}  \\\hline
\CU-\product-SUBSYST-SCOPE-XX-YY &
Description of the test case \\\hline
\end{longtable}

\subsection{Feature pass/fail criteria \label{sect:passfail}}
Specify the specific criteria for this design to be used to determine whether the feature or feature combination has passed or failed.


%\newpage

%--------------------------------------------------
% TEST CASE SPECIFICATION
%--------------------------------------------------
%\subsection{Test Case Specification \label{sect:testcases}}
%Define the test cases identified by a test design specification. For each identify test case specify:

%\newpage

\subsection{Test Case \CU-\product-SUBSYST-SCOPE-XX-YY \label{sect:testcaseid}}

\subsubsection{Requirements \label{sect:reqs}}
Specify the requirements that fulfill the test cases, comma-separated and ending with '.'\\
e.g. CU3-IDT-XM-FUN-30,CU3-IDT-ASD-FUN-20.\\
Note that the format is essential for the script that creates the traceability matrices works fine.

\subsubsection{Test items \label{sect:tcitems}}
Identify and briefly describe the items and features to be exercised by this test case.\\
For each item, consider supplying references to the following test item documentation: requirements specification, design
specification, user guide, operations guide, installation guide, etc.

\subsubsection{Input specification \label{sect:tcinput}}
Specify each input required to execute the test case. Some of the inputs will be specified by value (with tolerances where 
appropriate), while others will be specified by name.\\
Identify all appropriate databases, files, terminal messages, memory resident areas, and values passed by the operating system.\\
Specify all required relationships between inputs (e.g. timing).

\subsubsection{Output specification \label{sect:tcoutput}}
Specify all the outputs and features (e.g. response time) required of the test items. 

\subsubsection{Environmental needs \label{sect:tcenvironment}}
\paragraph{Hardware \label{sect:tchw}}
Specify the characteristics and configurations of the hardware required to execute this test case.
\paragraph{Software \label{sect:tcsw}}
Specify the system and application software required to execute this test case. This may include system software such as operating
systems, compilers, simulators, and test tools.
\paragraph{Other \label{sect:tcother}}
Any other special requirements such as unique facility needs or specially trained personnel.

\subsubsection{Intercase dependencies \label{interface_dependencies}}
List the identifiers of the test cases that must be executed prior to this test case. Summarize the nature of the dependencies.

\subsubsection{Procedure \label{procedures}}
If the procedure is shared by various test cases it would be recommended to separate the procedure description from the test
case definition. Thus, only a reference to the procedure identification shall be provided. The complete description of 
the test procedure shall be given otherwise. \\

Describe any special constraints on the test procedures that execute this test case. These constraints may involve special set
up, operator intervention, output determination procedures, and special wrap up.

\newpage

%-----------------------------------------
% PROCEDURES
%-----------------------------------------
\section{Test Procedure Specification \label{proc_spec}}

This section could be removed if the test cases specification describe their specific procedure, i.e. the procedure is included
in the test case definition.

\subsection{Introduction \label{sect:peroc_intro}}
The purpose is to specify the steps for executing a set of test cases or, more generally, the steps used to analyze a software in order
to evaluate a set of features.\\
For every test procedure:

\subsection{[PROCEDURE IDENTIFIER] \label{sect:procedureid}}

\subsubsection{Purpose \label{sect:proc_purpose}}
Describe the purpose of this procedure. Provide the reference of the test cases that are executed by the procedure.

\subsubsection{Special requirements \label{sect:proc_reqs}}
Identify any special requirements that are necessary for the execution of this procedure. These may include prerequisite procedures, 
special skills requirements and special environmental requirements.

\subsubsection{Procedure steps \label{sect:proc_steps}}
Describe every step of each procedure execution. Include the following steps as applicable:
\paragraph{Log \label{sect:proc_log}}
Describe any special methods or format for logging the results of test execution, the incidents observed, and any other events
pertinent to the test.
\paragraph{Set up \label{sect:proc_setup}}
Describe the sequence of actions necessary to set up the procedure execution.
\paragraph{Start \label{sect:proc_start}}
Describe the actions necessary to begin the procedure execution.
\paragraph{Proceed \label{sect:proc_proceed}}
Describe the actions necessary during the procedure execution.
\paragraph{Measure \label{sect:proc_measure}}
Describe how the test measurements is made.
\paragraph{Shut down \label{sect:proc_shutdown}}
Describe the action necessary to suspend testing when interruption is forced by unscheduled events.
\paragraph{Restart \label{sect:proc_restart}}
Identify any procedural restart points and describe the actions necessary to restart the procedure at each of these points.
\paragraph{Wrap up \label{sect:proc_wrapup}}
Describe the actions necessary to terminate testing.
\paragraph{Contingencies \label{sect:proc_contingencies}}
Describe the actions necessary to deal with anomalous events that may occur during execution.


\newpage

\appendix
\section{TRACEABILITY \label{sect:traceability}}
The backward and forward traceability (i.e. requirements trace to a test and a test to a requirement, respectively) shall be provided in order to 
ascertain the correlations between the test cases and the requirements they fulfill.\\ 
They can be created using the ant target: {\it ststrace}\\
{\it ant -Dsts="abs path for STS tex" ststrace}\\
It is necessary that DOCCOMMON/scripts directory is in the PATH. The target must be run under the directory where the SRS is located.\\

e.g.\\
ant -Dsts="../STS/GAIA-C3-SP-ESAC-RG-012.tex" ststrace \\
This target calls:\\
{\it MakeReqList.rb} to create the Requirements.csv and,\\
{\it system\_tests\_traceability.rb -d Requirements.csv -s (abs path for STS tex)}

\subsection{Forward Traceability Matrix}
Call the {\it SystemTestReqTable.tex} created

\subsection{Backward Traceability Matrix} 
Call the {\it SystemTestReqTableInvers.tex} created

\subsection{Other verification methods}
According the SVTP \citellp{LL:RG-004}, the software verification and validation in DPAC employs reviews, inspections, analysis and testing techniques
to determine whether the software system comply with requirements.\\
This section provides the traceability for those requirements that are not completely verified by testing. The information provided is:
\begin{itemize}
\item SRS Requirement
\item Verification method (following the VV Strategy of \citell{LL:RG-004}): Inspection (I), Review of the design (R), Analysis (A)
\item The requirement is completely verified with the stated method, or only partially (need of testing)
\end{itemize}

\begin{longtable}{|p{0.44\textwidth}|p{0.2\textwidth}|p{0.3\textwidth}|
}\hline
{\bf SRS Requirement} & {\bf Verification Method} & {\bf Partially/Completely Verified}
\\\hline
\end{longtable} \normalsize


\end{document}
